{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from glob import glob\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import cv2\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15021 entries, 0 to 15020\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   class_name  15021 non-null  object\n",
      " 1   image_path  15021 non-null  object\n",
      " 2   target      15021 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 352.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "   class_name                image_path  target\n",
       " 0  n01872401  n01872401/sketch_50.JPEG      59\n",
       " 1  n02417914  n02417914/sketch_11.JPEG     202\n",
       " 2  n02106166   n02106166/sketch_3.JPEG     138\n",
       " 3  n04235860   n04235860/sketch_2.JPEG     382\n",
       " 4  n02056570  n02056570/sketch_40.JPEG      80)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:/Users/zin/CV')\n",
    "\n",
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정\n",
    "traindata_dir = \"./data/train\"\n",
    "traindata_info_file = \"./data/train.csv\"\n",
    "\n",
    "# 테스트 데이터의 경로와 정보를 가진 파일의 경로를 설정\n",
    "testdata_dir = \"./data/test\"\n",
    "testdata_info_file = \"./data/test.csv\"\n",
    "\n",
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기\n",
    "train_data = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 테스트 데이터\n",
    "test_data = pd.read_csv(testdata_info_file)\n",
    "\n",
    "# 학습 데이터의 정보를 출력\n",
    "train_info = train_data.info()\n",
    "train_head = train_data.head()\n",
    "\n",
    "train_info, train_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       class_name                image_path        target\n",
       " count       15021                     15021  15021.000000\n",
       " unique        500                     15021           NaN\n",
       " top     n04532106  n01872401/sketch_50.JPEG           NaN\n",
       " freq           31                         1           NaN\n",
       " mean          NaN                       NaN    249.989082\n",
       " std           NaN                       NaN    144.471752\n",
       " min           NaN                       NaN      0.000000\n",
       " 25%           NaN                       NaN    125.000000\n",
       " 50%           NaN                       NaN    250.000000\n",
       " 75%           NaN                       NaN    375.000000\n",
       " max           NaN                       NaN    499.000000,\n",
       " 500,\n",
       " 500)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터의 기본적인 통계 정보를 출력\n",
    "data_description = train_data.describe(include='all')\n",
    "\n",
    "# class_name의 unique한 값의 개수를 출력\n",
    "unique_classes = train_data['class_name'].nunique()\n",
    "\n",
    "# target의 unique한 값의 개수를 출력\n",
    "unique_targets = train_data['target'].nunique()\n",
    "\n",
    "data_description, unique_classes, unique_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 class, image path, target에 대한 정보가 들어있는 csv파일을 읽기.\n",
    "train_info = pd.read_csv(traindata_info_file)\n",
    "\n",
    "# 총 class의 수를 측정.\n",
    "num_classes = len(train_info['target'].unique())\n",
    "\n",
    "# 각 class별로 8:2의 비율이 되도록 학습과 검증 데이터를 분리.\n",
    "train_df, val_df = train_test_split(\n",
    "    train_info, \n",
    "    test_size=0.2,\n",
    "    stratify=train_info['target']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 사용할 Transform을 선언.\n",
    "transform_selector = TransformSelector(\n",
    "    transform_type = \"albumentations\"\n",
    ")\n",
    "train_transform = transform_selector.get_transform(is_train=True)\n",
    "val_transform = transform_selector.get_transform(is_train=False)\n",
    "\n",
    "# 학습에 사용할 Dataset을 선언.\n",
    "train_dataset = CustomDataset(\n",
    "    root_dir=traindata_dir,\n",
    "    info_df=train_df,\n",
    "    transform=train_transform\n",
    ")\n",
    "val_dataset = CustomDataset(\n",
    "    root_dir=traindata_dir,\n",
    "    info_df=val_df,\n",
    "    transform=val_transform\n",
    ")\n",
    "\n",
    "# 학습에 사용할 DataLoader를 선언.\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# 학습에 사용할 장비를 선택.\n",
    "# torch라이브러리에서 gpu를 인식할 경우, cuda로 설정.\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\zin\\anaconda3\\envs\\p312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "c:\\Users\\zin\\anaconda3\\envs\\p312\\Lib\\site-packages\\transformers\\models\\clip\\modeling_clip.py:480: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "model.to(device)\n",
    "\n",
    "train_dataset = CLIPDataset(\n",
    "    root_dir=traindata_dir,\n",
    "    info_df=train_df,\n",
    "    transform=train_transform,\n",
    "    processor=processor,\n",
    "    device=device\n",
    ")\n",
    "inference = CLIPDataset(\n",
    "    root_dir=traindata_dir,\n",
    "    info_df=train_df,\n",
    "    transform=train_transform,\n",
    "    processor=processor,\n",
    "    device=device,\n",
    "    is_inference=True\n",
    ")\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=64, \n",
    "    shuffle=True\n",
    ")\n",
    "mini_values=get_imagenet_ditction(mini=True,values=True)\n",
    "mini_dict=get_imagenet_ditction(mini=True,values=False)\n",
    "outputs = model(**train_dataset[3])\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "probs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a photo of echidna, spiny anteater, anteater',\n",
       " 'a photo of ibex, Capra ibex',\n",
       " 'a photo of Border collie',\n",
       " 'a photo of sleeping bag',\n",
       " 'a photo of king penguin, Aptenodytes patagonica',\n",
       " 'a photo of mushroom',\n",
       " 'a photo of West Highland white terrier',\n",
       " 'a photo of Scotch terrier, Scottish terrier, Scottie',\n",
       " 'a photo of ox',\n",
       " 'a photo of torch',\n",
       " 'a photo of water buffalo, water ox, Asiatic buffalo, Bubalus bubalis',\n",
       " 'a photo of volcano',\n",
       " 'a photo of printer',\n",
       " 'a photo of notebook, notebook computer',\n",
       " 'a photo of Indian cobra, Naja naja',\n",
       " 'a photo of Dandie Dinmont, Dandie Dinmont terrier',\n",
       " 'a photo of wood rabbit, cottontail, cottontail rabbit',\n",
       " 'a photo of oscilloscope, scope, cathode-ray oscilloscope, CRO',\n",
       " 'a photo of hammer',\n",
       " 'a photo of ambulance',\n",
       " 'a photo of red-breasted merganser, Mergus serrator',\n",
       " 'a photo of American alligator, Alligator mississipiensis',\n",
       " 'a photo of white wolf, Arctic wolf, Canis lupus tundrarum',\n",
       " 'a photo of tailed frog, bell toad, ribbed toad, tailed toad, Ascaphus trui',\n",
       " 'a photo of Greater Swiss Mountain dog',\n",
       " 'a photo of muzzle',\n",
       " 'a photo of squirrel monkey, Saimiri sciureus',\n",
       " 'a photo of red-backed sandpiper, dunlin, Erolia alpina',\n",
       " 'a photo of stage',\n",
       " 'a photo of iron, smoothing iron',\n",
       " 'a photo of jacamar',\n",
       " 'a photo of honeycomb',\n",
       " 'a photo of barber chair',\n",
       " 'a photo of triumphal arch',\n",
       " 'a photo of rock python, rock snake, Python sebae',\n",
       " 'a photo of coffeepot',\n",
       " 'a photo of pug, pug-dog',\n",
       " 'a photo of umbrella',\n",
       " 'a photo of mailbox, letter box',\n",
       " 'a photo of jay',\n",
       " 'a photo of hen-of-the-woods, hen of the woods, Polyporus frondosus, Grifola frondosa',\n",
       " 'a photo of monarch, monarch butterfly, milkweed butterfly, Danaus plexippus',\n",
       " 'a photo of stretcher',\n",
       " 'a photo of French bulldog',\n",
       " 'a photo of vacuum, vacuum cleaner',\n",
       " 'a photo of banana',\n",
       " 'a photo of cello, violoncello',\n",
       " 'a photo of goldfinch, Carduelis carduelis',\n",
       " 'a photo of wild boar, boar, Sus scrofa',\n",
       " 'a photo of go-kart',\n",
       " 'a photo of bald eagle, American eagle, Haliaeetus leucocephalus',\n",
       " 'a photo of racket, racquet',\n",
       " 'a photo of parallel bars, bars',\n",
       " 'a photo of gas pump, gasoline pump, petrol pump, island dispenser',\n",
       " 'a photo of passenger car, coach, carriage',\n",
       " 'a photo of agaric',\n",
       " 'a photo of Rhodesian ridgeback',\n",
       " 'a photo of standard schnauzer',\n",
       " 'a photo of sombrero',\n",
       " 'a photo of golf ball',\n",
       " 'a photo of radiator',\n",
       " 'a photo of armadillo',\n",
       " 'a photo of carton',\n",
       " 'a photo of pick, plectrum, plectron',\n",
       " 'a photo of airliner',\n",
       " 'a photo of black widow, Latrodectus mactans',\n",
       " 'a photo of croquet ball',\n",
       " 'a photo of Japanese spaniel',\n",
       " 'a photo of television, television system',\n",
       " 'a photo of cock',\n",
       " 'a photo of vending machine',\n",
       " 'a photo of water jug',\n",
       " 'a photo of laptop, laptop computer',\n",
       " 'a photo of impala, Aepyceros melampus',\n",
       " 'a photo of crayfish, crawfish, crawdad, crawdaddy',\n",
       " 'a photo of studio couch, day bed',\n",
       " 'a photo of spaghetti squash',\n",
       " 'a photo of can opener, tin opener',\n",
       " 'a photo of padlock',\n",
       " 'a photo of horned viper, cerastes, sand viper, horned asp, Cerastes cornutus',\n",
       " 'a photo of lionfish',\n",
       " 'a photo of restaurant, eating house, eating place, eatery',\n",
       " 'a photo of basenji',\n",
       " 'a photo of American egret, great white heron, Egretta albus',\n",
       " 'a photo of hammerhead, hammerhead shark',\n",
       " 'a photo of skunk, polecat, wood pussy',\n",
       " 'a photo of scuba diver',\n",
       " 'a photo of flagpole, flagstaff',\n",
       " 'a photo of shopping cart',\n",
       " 'a photo of Windsor tie',\n",
       " 'a photo of monastery',\n",
       " 'a photo of purse',\n",
       " 'a photo of geyser',\n",
       " 'a photo of toy poodle',\n",
       " 'a photo of Pembroke, Pembroke Welsh corgi',\n",
       " 'a photo of toucan',\n",
       " 'a photo of sax, saxophone',\n",
       " 'a photo of fire engine, fire truck',\n",
       " 'a photo of American lobster, Northern lobster, Maine lobster, Homarus americanus',\n",
       " 'a photo of sea slug, nudibranch',\n",
       " 'a photo of Weimaraner',\n",
       " 'a photo of hognose snake, puff adder, sand viper',\n",
       " 'a photo of crib, cot',\n",
       " 'a photo of wreck',\n",
       " 'a photo of Welsh springer spaniel',\n",
       " 'a photo of vulture',\n",
       " 'a photo of suit, suit of clothes',\n",
       " 'a photo of house finch, linnet, Carpodacus mexicanus',\n",
       " 'a photo of sea cucumber, holothurian',\n",
       " 'a photo of water ouzel, dipper',\n",
       " 'a photo of safety pin',\n",
       " 'a photo of jigsaw puzzle',\n",
       " 'a photo of bikini, two-piece',\n",
       " 'a photo of alp',\n",
       " 'a photo of guinea pig, Cavia cobaya',\n",
       " 'a photo of coffee mug',\n",
       " 'a photo of book jacket, dust cover, dust jacket, dust wrapper',\n",
       " 'a photo of corkscrew, bottle screw',\n",
       " 'a photo of frilled lizard, Chlamydosaurus kingi',\n",
       " 'a photo of white stork, Ciconia ciconia',\n",
       " 'a photo of miniskirt, mini',\n",
       " 'a photo of steam locomotive',\n",
       " 'a photo of golfcart, golf cart',\n",
       " 'a photo of Brittany spaniel',\n",
       " 'a photo of racer, race car, racing car',\n",
       " 'a photo of tennis ball',\n",
       " 'a photo of diaper, nappy, napkin',\n",
       " 'a photo of running shoe',\n",
       " 'a photo of quail',\n",
       " 'a photo of Great Dane',\n",
       " 'a photo of saltshaker, salt shaker',\n",
       " 'a photo of platypus, duckbill, duckbilled platypus, duck-billed platypus, Ornithorhynchus anatinus',\n",
       " 'a photo of volleyball',\n",
       " 'a photo of Chihuahua',\n",
       " \"a photo of spider web, spider's web\",\n",
       " 'a photo of gar, garfish, garpike, billfish, Lepisosteus osseus',\n",
       " \"a photo of dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk\",\n",
       " 'a photo of junco, snowbird',\n",
       " 'a photo of groenendael',\n",
       " 'a photo of backpack, back pack, knapsack, packsack, rucksack, haversack',\n",
       " 'a photo of tarantula',\n",
       " 'a photo of bison',\n",
       " 'a photo of military uniform',\n",
       " 'a photo of loudspeaker, speaker, speaker unit, loudspeaker system, speaker system',\n",
       " 'a photo of koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus',\n",
       " 'a photo of coral reef',\n",
       " 'a photo of Saint Bernard, St Bernard',\n",
       " 'a photo of kelpie',\n",
       " 'a photo of Arabian camel, dromedary, Camelus dromedarius',\n",
       " 'a photo of caldron, cauldron',\n",
       " 'a photo of mosquito net',\n",
       " 'a photo of liner, ocean liner',\n",
       " 'a photo of Shetland sheepdog, Shetland sheep dog, Shetland',\n",
       " 'a photo of envelope',\n",
       " 'a photo of green mamba',\n",
       " 'a photo of stole',\n",
       " 'a photo of bighorn, bighorn sheep, cimarron, Rocky Mountain bighorn, Rocky Mountain sheep, Ovis canadensis',\n",
       " 'a photo of folding chair',\n",
       " 'a photo of barn',\n",
       " 'a photo of bustard',\n",
       " 'a photo of washbasin, handbasin, washbowl, lavabo, wash-hand basin',\n",
       " 'a photo of stethoscope',\n",
       " 'a photo of table lamp',\n",
       " 'a photo of hummingbird',\n",
       " 'a photo of breastplate, aegis, egis',\n",
       " 'a photo of sorrel',\n",
       " 'a photo of ping-pong ball',\n",
       " 'a photo of Norfolk terrier',\n",
       " 'a photo of tiger, Panthera tigris',\n",
       " 'a photo of thresher, thrasher, threshing machine',\n",
       " 'a photo of perfume, essence',\n",
       " 'a photo of stone wall',\n",
       " 'a photo of brass, memorial tablet, plaque',\n",
       " 'a photo of prison, prison house',\n",
       " 'a photo of acorn squash',\n",
       " 'a photo of snowplow, snowplough',\n",
       " 'a photo of washer, automatic washer, washing machine',\n",
       " 'a photo of black-footed ferret, ferret, Mustela nigripes',\n",
       " 'a photo of macaw',\n",
       " 'a photo of accordion, piano accordion, squeeze box',\n",
       " 'a photo of missile',\n",
       " 'a photo of standard poodle',\n",
       " 'a photo of English setter',\n",
       " 'a photo of kuvasz',\n",
       " 'a photo of sweatshirt',\n",
       " 'a photo of plate',\n",
       " 'a photo of toilet seat',\n",
       " 'a photo of microphone, mike',\n",
       " 'a photo of keeshond',\n",
       " 'a photo of seat belt, seatbelt',\n",
       " 'a photo of German short-haired pointer',\n",
       " 'a photo of sea snake',\n",
       " 'a photo of American black bear, black bear, Ursus americanus, Euarctos americanus',\n",
       " 'a photo of mantis, mantid',\n",
       " 'a photo of chickadee',\n",
       " 'a photo of worm fence, snake fence, snake-rail fence, Virginia fence',\n",
       " 'a photo of bittern',\n",
       " 'a photo of miniature schnauzer',\n",
       " 'a photo of buckeye, horse chestnut, conker',\n",
       " 'a photo of packet',\n",
       " 'a photo of zucchini, courgette',\n",
       " 'a photo of pier',\n",
       " 'a photo of trench coat',\n",
       " 'a photo of confectionery, confectionary, candy store',\n",
       " 'a photo of poncho',\n",
       " 'a photo of crate',\n",
       " 'a photo of shower curtain',\n",
       " 'a photo of sarong',\n",
       " 'a photo of polecat, fitch, foulmart, foumart, Mustela putorius',\n",
       " 'a photo of typewriter keyboard',\n",
       " 'a photo of Norwich terrier',\n",
       " 'a photo of ski mask',\n",
       " 'a photo of Walker hound, Walker foxhound',\n",
       " 'a photo of Scottish deerhound, deerhound',\n",
       " 'a photo of espresso',\n",
       " 'a photo of fire screen, fireguard',\n",
       " 'a photo of flat-coated retriever',\n",
       " 'a photo of basketball',\n",
       " 'a photo of vine snake',\n",
       " 'a photo of hourglass',\n",
       " 'a photo of Boston bull, Boston terrier',\n",
       " 'a photo of malinois',\n",
       " 'a photo of tub, vat',\n",
       " 'a photo of analog clock',\n",
       " 'a photo of park bench',\n",
       " 'a photo of shovel',\n",
       " 'a photo of quill, quill pen',\n",
       " 'a photo of bluetick',\n",
       " 'a photo of wardrobe, closet, press',\n",
       " 'a photo of wok',\n",
       " 'a photo of pole',\n",
       " 'a photo of whippet',\n",
       " 'a photo of jackfruit, jak, jack',\n",
       " 'a photo of Dungeness crab, Cancer magister',\n",
       " 'a photo of apiary, bee house',\n",
       " 'a photo of dhole, Cuon alpinus',\n",
       " 'a photo of soup bowl',\n",
       " 'a photo of hair slide',\n",
       " 'a photo of tray',\n",
       " 'a photo of sea lion',\n",
       " 'a photo of mousetrap',\n",
       " 'a photo of thunder snake, worm snake, Carphophis amoenus',\n",
       " 'a photo of whistle',\n",
       " 'a photo of cellular telephone, cellular phone, cellphone, cell, mobile phone',\n",
       " 'a photo of bolete',\n",
       " 'a photo of dough',\n",
       " 'a photo of dishwasher, dish washer, dishwashing machine',\n",
       " 'a photo of ice lolly, lolly, lollipop, popsicle',\n",
       " 'a photo of Sussex spaniel',\n",
       " 'a photo of jellyfish',\n",
       " 'a photo of vestment',\n",
       " 'a photo of space shuttle',\n",
       " 'a photo of safe',\n",
       " 'a photo of brambling, Fringilla montifringilla',\n",
       " 'a photo of wool, woolen, woollen',\n",
       " 'a photo of tile roof',\n",
       " 'a photo of giant schnauzer',\n",
       " 'a photo of red wolf, maned wolf, Canis rufus, Canis niger',\n",
       " 'a photo of electric fan, blower',\n",
       " 'a photo of mask',\n",
       " 'a photo of cairn, cairn terrier',\n",
       " 'a photo of unicycle, monocycle',\n",
       " 'a photo of bee eater',\n",
       " 'a photo of vizsla, Hungarian pointer',\n",
       " 'a photo of harvester, reaper',\n",
       " 'a photo of shower cap',\n",
       " 'a photo of bullet train, bullet',\n",
       " 'a photo of broom',\n",
       " 'a photo of assault rifle, assault gun',\n",
       " 'a photo of black swan, Cygnus atratus',\n",
       " 'a photo of indigo bunting, indigo finch, indigo bird, Passerina cyanea',\n",
       " 'a photo of lampshade, lamp shade',\n",
       " 'a photo of brown bear, bruin, Ursus arctos',\n",
       " 'a photo of Afghan hound, Afghan',\n",
       " 'a photo of football helmet',\n",
       " 'a photo of shoji',\n",
       " 'a photo of goose',\n",
       " 'a photo of axolotl, mud puppy, Ambystoma mexicanum',\n",
       " 'a photo of drum, membranophone, tympan',\n",
       " 'a photo of trombone',\n",
       " 'a photo of brassiere, bra, bandeau',\n",
       " 'a photo of school bus',\n",
       " 'a photo of weasel',\n",
       " 'a photo of pizza, pizza pie',\n",
       " 'a photo of Norwegian elkhound, elkhound',\n",
       " 'a photo of partridge',\n",
       " 'a photo of bathtub, bathing tub, bath, tub',\n",
       " 'a photo of basset, basset hound',\n",
       " 'a photo of Siberian husky',\n",
       " 'a photo of bullfrog, Rana catesbeiana',\n",
       " 'a photo of scorpion',\n",
       " 'a photo of redbone',\n",
       " 'a photo of three-toed sloth, ai, Bradypus tridactylus',\n",
       " 'a photo of scale, weighing machine',\n",
       " 'a photo of black grouse',\n",
       " 'a photo of plastic bag',\n",
       " 'a photo of tripod',\n",
       " 'a photo of puck, hockey puck',\n",
       " 'a photo of Yorkshire terrier',\n",
       " 'a photo of sundial',\n",
       " 'a photo of Komodo dragon, Komodo lizard, dragon lizard, giant lizard, Varanus komodoensis',\n",
       " 'a photo of planetarium',\n",
       " 'a photo of African crocodile, Nile crocodile, Crocodylus niloticus',\n",
       " 'a photo of dung beetle',\n",
       " 'a photo of fountain',\n",
       " 'a photo of ostrich, Struthio camelus',\n",
       " 'a photo of power drill',\n",
       " 'a photo of window screen',\n",
       " 'a photo of sock',\n",
       " 'a photo of wig',\n",
       " 'a photo of wine bottle',\n",
       " 'a photo of rule, ruler',\n",
       " 'a photo of Italian greyhound',\n",
       " 'a photo of throne',\n",
       " 'a photo of spider monkey, Ateles geoffroyi',\n",
       " 'a photo of chain',\n",
       " 'a photo of groom, bridegroom',\n",
       " 'a photo of cowboy boot',\n",
       " 'a photo of aircraft carrier, carrier, flattop, attack aircraft carrier',\n",
       " 'a photo of titi, titi monkey',\n",
       " 'a photo of wolf spider, hunting spider',\n",
       " 'a photo of shield, buckler',\n",
       " 'a photo of albatross, mollymawk',\n",
       " 'a photo of jersey, T-shirt, tee shirt',\n",
       " 'a photo of vault',\n",
       " 'a photo of necklace',\n",
       " 'a photo of ram, tup',\n",
       " 'a photo of ballplayer, baseball player',\n",
       " 'a photo of remote control, remote',\n",
       " 'a photo of golden retriever',\n",
       " 'a photo of Irish setter, red setter',\n",
       " 'a photo of night snake, Hypsiglena torquata',\n",
       " 'a photo of kite',\n",
       " 'a photo of oystercatcher, oyster catcher',\n",
       " 'a photo of colobus, colobus monkey',\n",
       " 'a photo of boxer',\n",
       " 'a photo of syringe',\n",
       " 'a photo of beach wagon, station wagon, wagon, estate car, beach waggon, station waggon, waggon',\n",
       " 'a photo of Granny Smith',\n",
       " 'a photo of Newfoundland, Newfoundland dog',\n",
       " \"a photo of loupe, jeweler's loupe\",\n",
       " 'a photo of artichoke, globe artichoke',\n",
       " 'a photo of vase',\n",
       " 'a photo of rain barrel',\n",
       " 'a photo of Rottweiler',\n",
       " 'a photo of theater curtain, theatre curtain',\n",
       " 'a photo of beagle',\n",
       " 'a photo of lipstick, lip rouge',\n",
       " 'a photo of switch, electric switch, electrical switch',\n",
       " 'a photo of barrel, cask',\n",
       " 'a photo of giant panda, panda, panda bear, coon bear, Ailuropoda melanoleuca',\n",
       " 'a photo of car wheel',\n",
       " 'a photo of lycaenid, lycaenid butterfly',\n",
       " 'a photo of common iguana, iguana, Iguana iguana',\n",
       " 'a photo of garden spider, Aranea diademata',\n",
       " 'a photo of tabby, tabby cat',\n",
       " 'a photo of chambered nautilus, pearly nautilus, nautilus',\n",
       " 'a photo of tractor',\n",
       " 'a photo of pedestal, plinth, footstall',\n",
       " 'a photo of baseball',\n",
       " 'a photo of crossword puzzle, crossword',\n",
       " 'a photo of altar',\n",
       " 'a photo of lion, king of beasts, Panthera leo',\n",
       " 'a photo of guacamole',\n",
       " 'a photo of mitten',\n",
       " 'a photo of microwave, microwave oven',\n",
       " 'a photo of beacon, lighthouse, beacon light, pharos',\n",
       " 'a photo of lawn mower, mower',\n",
       " 'a photo of Staffordshire bullterrier, Staffordshire bull terrier',\n",
       " 'a photo of cheetah, chetah, Acinonyx jubatus',\n",
       " 'a photo of English springer, English springer spaniel',\n",
       " 'a photo of violin, fiddle',\n",
       " 'a photo of apron',\n",
       " 'a photo of daisy',\n",
       " 'a photo of macaque',\n",
       " 'a photo of cocker spaniel, English cocker spaniel, cocker',\n",
       " 'a photo of broccoli',\n",
       " 'a photo of yawl',\n",
       " 'a photo of prayer rug, prayer mat',\n",
       " 'a photo of harvestman, daddy longlegs, Phalangium opilio',\n",
       " 'a photo of ice bear, polar bear, Ursus Maritimus, Thalarctos maritimus',\n",
       " 'a photo of butcher shop, meat market',\n",
       " 'a photo of reflex camera',\n",
       " 'a photo of mortarboard',\n",
       " 'a photo of Samoyed, Samoyede',\n",
       " 'a photo of mouse, computer mouse',\n",
       " 'a photo of potpie',\n",
       " 'a photo of little blue heron, Egretta caerulea',\n",
       " 'a photo of Shih-Tzu',\n",
       " 'a photo of cauliflower',\n",
       " 'a photo of acoustic guitar',\n",
       " 'a photo of tobacco shop, tobacconist shop, tobacconist',\n",
       " 'a photo of trimaran',\n",
       " 'a photo of lab coat, laboratory coat',\n",
       " 'a photo of hare',\n",
       " 'a photo of Egyptian cat',\n",
       " 'a photo of cabbage butterfly',\n",
       " 'a photo of marmot',\n",
       " 'a photo of airship, dirigible',\n",
       " 'a photo of water bottle',\n",
       " 'a photo of acorn',\n",
       " 'a photo of ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle',\n",
       " 'a photo of chow, chow chow',\n",
       " 'a photo of sea anemone, anemone',\n",
       " 'a photo of garter snake, grass snake',\n",
       " 'a photo of snail',\n",
       " 'a photo of hatchet',\n",
       " 'a photo of sunglasses, dark glasses, shades',\n",
       " 'a photo of English foxhound',\n",
       " 'a photo of Siamese cat, Siamese',\n",
       " 'a photo of soccer ball',\n",
       " 'a photo of Great Pyrenees',\n",
       " 'a photo of French horn, horn',\n",
       " 'a photo of strawberry',\n",
       " 'a photo of mailbag, postbag',\n",
       " 'a photo of ice cream, icecream',\n",
       " 'a photo of triceratops',\n",
       " 'a photo of mountain bike, all-terrain bike, off-roader',\n",
       " 'a photo of bow tie, bow-tie, bowtie',\n",
       " 'a photo of Gordon setter',\n",
       " 'a photo of tree frog, tree-frog',\n",
       " 'a photo of suspension bridge',\n",
       " 'a photo of bow',\n",
       " 'a photo of corn',\n",
       " 'a photo of trifle',\n",
       " 'a photo of swimming trunks, bathing trunks',\n",
       " 'a photo of hoopskirt, crinoline',\n",
       " 'a photo of gown',\n",
       " 'a photo of pillow',\n",
       " 'a photo of goldfish, Carassius auratus',\n",
       " 'a photo of Pekinese, Pekingese, Peke',\n",
       " 'a photo of zebra',\n",
       " 'a photo of hippopotamus, hippo, river horse, Hippopotamus amphibius',\n",
       " 'a photo of American Staffordshire terrier, Staffordshire terrier, American pit bull terrier, pit bull terrier',\n",
       " 'a photo of Doberman, Doberman pinscher',\n",
       " 'a photo of disk brake, disc brake',\n",
       " 'a photo of teddy, teddy bear',\n",
       " 'a photo of rugby ball',\n",
       " 'a photo of sunglass',\n",
       " 'a photo of stove',\n",
       " 'a photo of cloak',\n",
       " 'a photo of leopard, Panthera pardus',\n",
       " 'a photo of toaster',\n",
       " 'a photo of fox squirrel, eastern fox squirrel, Sciurus niger',\n",
       " \"a photo of plunger, plumber's helper\",\n",
       " 'a photo of Bernese mountain dog',\n",
       " 'a photo of pool table, billiard table, snooker table',\n",
       " 'a photo of hamster',\n",
       " 'a photo of cliff, drop, drop-off',\n",
       " 'a photo of timber wolf, grey wolf, gray wolf, Canis lupus',\n",
       " 'a photo of orange',\n",
       " 'a photo of miniature poodle',\n",
       " 'a photo of trolleybus, trolley coach, trackless trolley',\n",
       " 'a photo of slide rule, slipstick',\n",
       " 'a photo of bloodhound, sleuthhound',\n",
       " 'a photo of common newt, Triturus vulgaris',\n",
       " 'a photo of hyena, hyaena',\n",
       " 'a photo of turnstile',\n",
       " 'a photo of Lhasa, Lhasa apso',\n",
       " 'a photo of lynx, catamount',\n",
       " 'a photo of balloon',\n",
       " 'a photo of wallet, billfold, notecase, pocketbook',\n",
       " 'a photo of electric ray, crampfish, numbfish, torpedo',\n",
       " 'a photo of binoculars, field glasses, opera glasses',\n",
       " 'a photo of orangutan, orang, orangutang, Pongo pygmaeus',\n",
       " 'a photo of plate rack',\n",
       " 'a photo of collie',\n",
       " 'a photo of warthog',\n",
       " 'a photo of radio, wireless',\n",
       " 'a photo of bolo tie, bolo, bola tie, bola',\n",
       " 'a photo of espresso maker',\n",
       " 'a photo of boa constrictor, Constrictor constrictor',\n",
       " 'a photo of snowmobile',\n",
       " 'a photo of toy terrier',\n",
       " 'a photo of pomegranate',\n",
       " 'a photo of magpie',\n",
       " 'a photo of nematode, nematode worm, roundworm',\n",
       " 'a photo of robin, American robin, Turdus migratorius',\n",
       " 'a photo of mink',\n",
       " 'a photo of Old English sheepdog, bobtail',\n",
       " 'a photo of Arctic fox, white fox, Alopex lagopus',\n",
       " 'a photo of Maltese dog, Maltese terrier, Maltese',\n",
       " 'a photo of African chameleon, Chamaeleo chamaeleon',\n",
       " 'a photo of swing',\n",
       " 'a photo of gong, tam-tam',\n",
       " 'a photo of snorkel',\n",
       " 'a photo of great white shark, white shark, man-eater, man-eating shark, Carcharodon carcharias',\n",
       " 'a photo of flamingo',\n",
       " 'a photo of fig',\n",
       " 'a photo of ringlet, ringlet butterfly',\n",
       " 'a photo of maraca',\n",
       " 'a photo of pelican',\n",
       " 'a photo of borzoi, Russian wolfhound',\n",
       " 'a photo of Saluki, gazelle hound',\n",
       " 'a photo of birdhouse',\n",
       " 'a photo of sunscreen, sunblock, sun blocker',\n",
       " 'a photo of llama',\n",
       " 'a photo of bull mastiff',\n",
       " 'a photo of matchstick',\n",
       " 'a photo of bookcase']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mini_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[49406,   320,  1125,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  1125,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  1125,  ..., 49407, 49407, 49407],\n",
       "        ...,\n",
       "        [49406,   320,  1125,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  1125,  ..., 49407, 49407, 49407],\n",
       "        [49406,   320,  1125,  ..., 49407, 49407, 49407]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]], device='cuda:0'), 'pixel_values': tensor([[[[1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          ...,\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303],\n",
       "          [1.9303, 1.9303, 1.9303,  ..., 1.9303, 1.9303, 1.9303]],\n",
       "\n",
       "         [[2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          ...,\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749],\n",
       "          [2.0749, 2.0749, 2.0749,  ..., 2.0749, 2.0749, 2.0749]],\n",
       "\n",
       "         [[2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          ...,\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459],\n",
       "          [2.1459, 2.1459, 2.1459,  ..., 2.1459, 2.1459, 2.1459]]]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text_token=processor(text=mini_values,return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "#train_dataset[0]\n",
    "all_text_token\n",
    "all = all_text_token\n",
    "all['pixel_values'] = inference[0]['pixel_values']\n",
    "all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.4250e-06, 4.7808e-07, 1.4084e-07, 6.1026e-07, 1.2219e-06, 1.5618e-07,\n",
       "         1.3654e-07, 1.6591e-07, 1.0094e-06, 1.7757e-06, 3.8757e-06, 6.7103e-07,\n",
       "         4.3323e-06, 1.6178e-06, 1.7982e-08, 4.0184e-10, 1.0608e-06, 6.6154e-09,\n",
       "         5.4286e-07, 3.7540e-07, 3.2528e-10, 2.4911e-11, 5.8909e-07, 2.4358e-06,\n",
       "         4.9505e-09, 6.9927e-07, 3.0352e-09, 3.1255e-09, 5.0952e-06, 2.6914e-06,\n",
       "         3.6494e-05, 2.8568e-06, 5.4938e-08, 2.3865e-07, 5.4340e-07, 1.9723e-07,\n",
       "         9.8283e-09, 5.5792e-06, 8.3405e-08, 1.0832e-05, 1.0923e-08, 1.1829e-06,\n",
       "         2.5142e-06, 1.1750e-08, 2.2693e-06, 3.3161e-07, 2.4948e-05, 6.8290e-10,\n",
       "         1.3408e-06, 3.1438e-08, 2.3221e-07, 2.4480e-07, 2.8320e-06, 6.5495e-08,\n",
       "         2.4975e-06, 5.5090e-08, 7.0397e-07, 3.3545e-08, 3.4453e-06, 2.8976e-07,\n",
       "         4.6069e-07, 3.4328e-07, 4.0547e-06, 5.9967e-06, 3.8941e-07, 2.9734e-02,\n",
       "         3.1275e-06, 5.3336e-09, 1.4300e-05, 2.4754e-07, 1.1967e-07, 9.2541e-08,\n",
       "         1.1553e-06, 1.8598e-04, 1.3024e-05, 1.8962e-07, 1.6837e-06, 2.4014e-06,\n",
       "         1.5866e-06, 7.6090e-06, 5.0832e-08, 1.3469e-05, 3.1493e-09, 2.5889e-07,\n",
       "         1.2388e-06, 1.1610e-06, 1.7299e-07, 4.0962e-08, 3.5638e-07, 2.2362e-06,\n",
       "         1.5098e-07, 3.3616e-05, 5.7326e-08, 9.5134e-09, 1.5365e-09, 2.0807e-08,\n",
       "         2.4060e-08, 1.3639e-08, 4.0593e-05, 9.6868e-08, 1.3834e-07, 2.7596e-07,\n",
       "         1.0626e-06, 1.4747e-07, 2.8585e-09, 9.2429e-07, 5.8852e-05, 2.8785e-09,\n",
       "         2.0419e-06, 1.8252e-11, 1.2461e-06, 3.0044e-06, 7.9454e-08, 2.0843e-05,\n",
       "         1.5462e-10, 1.0371e-07, 3.6982e-06, 3.9060e-06, 4.3699e-08, 2.8840e-06,\n",
       "         9.8133e-07, 3.3734e-09, 2.7464e-08, 7.9939e-09, 2.0494e-07, 1.1064e-06,\n",
       "         5.5036e-06, 8.5644e-07, 1.3638e-07, 2.4893e-08, 5.0333e-06, 6.0090e-07,\n",
       "         8.1939e-07, 2.2269e-07, 3.7501e-04, 5.2165e-06, 2.8269e-04, 1.1201e-09,\n",
       "         1.9309e-06, 3.4269e-05, 8.3045e-04, 1.8693e-07, 3.8934e-07, 7.2439e-06,\n",
       "         1.1005e-04, 5.5248e-09, 1.6357e-09, 4.7052e-06, 9.9519e-07, 1.5708e-06,\n",
       "         2.6872e-04, 1.0943e-06, 1.6556e-09, 3.7152e-05, 3.2900e-07, 1.6609e-06,\n",
       "         2.5906e-06, 4.4671e-06, 9.7440e-09, 1.4508e-07, 1.9709e-07, 1.8205e-05,\n",
       "         2.2256e-06, 4.7593e-08, 6.7451e-06, 1.9792e-06, 2.2237e-05, 5.2315e-09,\n",
       "         1.4094e-08, 1.4484e-04, 2.0615e-05, 1.4270e-07, 1.0563e-07, 1.9902e-07,\n",
       "         1.9771e-07, 1.1056e-06, 1.9406e-06, 1.1909e-10, 1.6227e-08, 2.2108e-07,\n",
       "         3.3687e-07, 1.6102e-07, 5.1058e-10, 5.7539e-07, 1.1227e-05, 2.4302e-04,\n",
       "         4.3236e-07, 2.6663e-06, 2.2383e-09, 7.3160e-07, 3.9349e-08, 2.1603e-08,\n",
       "         5.5545e-07, 4.6123e-06, 5.7741e-09, 1.4672e-06, 2.8717e-06, 1.1875e-08,\n",
       "         4.8701e-06, 4.2008e-05, 5.1769e-08, 2.0415e-07, 6.3954e-06, 9.2423e-07,\n",
       "         2.8515e-05, 2.3769e-06, 3.1400e-06, 1.8324e-06, 4.5514e-06, 3.8660e-10,\n",
       "         2.1472e-08, 9.4401e-08, 2.3705e-07, 4.0559e-09, 4.3071e-07, 7.3581e-07,\n",
       "         4.3861e-08, 1.4056e-06, 4.8450e-07, 2.6519e-06, 1.4978e-08, 2.3685e-06,\n",
       "         7.0404e-07, 1.0877e-06, 6.4882e-08, 7.8918e-07, 1.6414e-05, 1.7936e-07,\n",
       "         1.6073e-05, 1.1531e-06, 2.6903e-05, 5.6609e-08, 1.3428e-07, 3.9138e-05,\n",
       "         9.4998e-07, 1.3648e-07, 1.0876e-07, 1.2416e-04, 1.3721e-06, 3.5074e-09,\n",
       "         4.1343e-06, 1.1793e-05, 1.0482e-06, 5.2443e-05, 4.5674e-08, 2.1719e-06,\n",
       "         4.9417e-06, 3.9447e-07, 2.6985e-10, 4.9204e-07, 1.3115e-05, 4.0332e-08,\n",
       "         3.0462e-06, 3.9047e-07, 4.0236e-05, 1.1246e-07, 8.9905e-08, 2.9461e-07,\n",
       "         2.5913e-06, 3.9436e-06, 1.9649e-09, 3.5475e-06, 7.0233e-07, 4.3830e-09,\n",
       "         1.2995e-06, 1.4641e-07, 3.8665e-08, 2.2466e-06, 4.3410e-07, 1.0231e-06,\n",
       "         1.0523e-07, 9.2873e-06, 3.8294e-07, 2.3676e-07, 3.4275e-07, 4.3725e-06,\n",
       "         2.2408e-07, 5.7342e-08, 6.5179e-04, 2.1525e-07, 7.9840e-06, 7.0497e-07,\n",
       "         2.6099e-08, 1.5326e-06, 4.1889e-09, 1.4000e-06, 5.4200e-07, 3.2288e-10,\n",
       "         3.6702e-09, 1.3880e-08, 7.2638e-06, 4.6065e-06, 2.4729e-05, 5.8282e-06,\n",
       "         2.2041e-07, 8.8743e-06, 4.8040e-04, 4.0614e-06, 2.1807e-07, 5.3433e-07,\n",
       "         5.4237e-07, 1.3869e-06, 3.8438e-08, 8.0611e-06, 1.2753e-07, 9.8789e-06,\n",
       "         7.3917e-07, 4.0613e-06, 3.2107e-07, 5.1416e-06, 8.1534e-08, 1.0461e-05,\n",
       "         1.1449e-08, 4.7892e-06, 2.2482e-06, 5.5405e-07, 3.5376e-04, 3.6891e-08,\n",
       "         5.8804e-06, 6.6557e-09, 1.7157e-02, 7.9888e-07, 4.6126e-07, 3.5930e-06,\n",
       "         1.3955e-06, 7.7522e-06, 1.6372e-06, 7.4260e-07, 5.8172e-07, 1.0560e-08,\n",
       "         2.7231e-08, 3.7810e-07, 5.3165e-06, 1.1761e-06, 1.8715e-08, 1.9057e-07,\n",
       "         5.1380e-06, 1.6789e-09, 1.1940e-07, 4.8435e-09, 8.2360e-06, 8.4170e-06,\n",
       "         8.9471e-07, 2.1035e-07, 6.7801e-08, 9.8804e-06, 1.8366e-07, 4.2343e-07,\n",
       "         8.9184e-06, 1.0241e-06, 1.3204e-05, 7.8001e-06, 9.7124e-06, 7.6582e-08,\n",
       "         2.5424e-02, 7.7636e-08, 3.8569e-09, 3.8853e-08, 6.2149e-10, 6.7620e-07,\n",
       "         1.8225e-06, 3.5883e-07, 5.6981e-09, 1.6287e-06, 8.8334e-07, 1.1867e-05,\n",
       "         2.1900e-06, 8.9877e-07, 3.5260e-08, 3.4841e-10, 3.2606e-08, 1.0495e-05,\n",
       "         3.7167e-06, 4.3730e-07, 6.0349e-07, 8.0910e-08, 2.1494e-08, 2.1184e-06,\n",
       "         8.1208e-08, 9.2129e-01, 9.5235e-06, 1.0950e-07, 1.8335e-06, 3.4042e-06,\n",
       "         1.3421e-08, 2.2789e-06, 3.4006e-07, 2.9871e-09, 2.2005e-08, 2.8340e-06,\n",
       "         2.6352e-07, 3.6950e-07, 1.9236e-06, 1.3267e-04, 1.1241e-07, 3.1714e-09,\n",
       "         1.3786e-06, 1.9304e-10, 1.8614e-07, 1.3295e-07, 1.1328e-07, 2.2819e-04,\n",
       "         1.2133e-07, 6.5241e-06, 1.6900e-07, 1.0194e-06, 4.3047e-07, 1.0570e-05,\n",
       "         1.3195e-06, 8.0219e-07, 2.9444e-07, 7.7089e-09, 2.4325e-07, 2.2383e-07,\n",
       "         1.2933e-05, 2.8588e-08, 1.3796e-06, 1.0436e-08, 3.5248e-06, 6.2052e-10,\n",
       "         2.6341e-06, 3.4452e-07, 9.7815e-05, 1.3677e-07, 9.9444e-08, 1.4999e-06,\n",
       "         7.8279e-05, 3.0861e-07, 1.2977e-05, 4.7593e-07, 1.1127e-07, 1.3255e-07,\n",
       "         9.1069e-07, 6.7303e-09, 9.1772e-08, 1.7248e-06, 3.3114e-08, 1.2740e-07,\n",
       "         2.4304e-06, 4.3398e-07, 1.4469e-06, 4.2749e-10, 2.9277e-07, 6.4587e-09,\n",
       "         1.9172e-07, 8.5369e-11, 1.2029e-06, 3.3680e-08, 9.0812e-07, 2.6424e-07,\n",
       "         5.1508e-06, 2.9009e-08, 1.0089e-06, 6.5989e-06, 8.0218e-08, 4.3283e-08,\n",
       "         5.4779e-08, 2.8268e-07, 2.3238e-08, 1.5063e-07, 2.0922e-06, 3.2371e-08,\n",
       "         1.1655e-06, 1.2192e-06, 6.5202e-05, 5.7201e-07, 3.6203e-07, 2.6433e-08,\n",
       "         3.9970e-06, 9.4640e-05, 2.1729e-07, 7.6453e-07, 2.5419e-07, 4.1440e-08,\n",
       "         6.7047e-07, 8.3816e-08, 1.5488e-04, 1.2802e-09, 4.9531e-08, 1.3047e-09,\n",
       "         2.1147e-07, 4.0648e-08, 2.5823e-09, 4.7278e-07, 9.0545e-06, 2.2022e-06,\n",
       "         7.7912e-06, 3.7037e-08, 1.5361e-05, 1.1189e-07, 9.1647e-07, 1.8446e-06,\n",
       "         7.5079e-10, 2.7109e-07, 6.8093e-07, 3.8175e-05, 6.5209e-08, 7.2271e-08,\n",
       "         6.1344e-05, 2.8060e-07]], device='cuda:0', grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**all)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1)  # we can take the softmax to get the label probabilities\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(probs[0])\n",
    "p=probs.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tarantula' 'wolf spider, hunting spider'\n",
      " 'garden spider, Aranea diademata' 'black widow, Latrodectus mactans'\n",
      " 'harvestman, daddy longlegs, Phalangium opilio']\n",
      "['harvestman, daddy longlegs, Phalangium opilio']\n"
     ]
    }
   ],
   "source": [
    "top_5 = np.argsort(p[0])[-5:]\n",
    "top_1 = np.argsort(p[0])[-1:]\n",
    "top_5_text = p[0][top_5]\n",
    "top_1_text = p[0][top_1]\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "#mini_values[mini_values_numpy]\n",
    "print(mini_values_numpy[top_5])\n",
    "print(mini_values_numpy[top_1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12016"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# images = [inference[i] for i in range(100)] #len(inference)\n",
    "# image_input = images#torch.stack(images).to(device)\n",
    "# text_input = all_text_token.to(device)\n",
    "len(inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'ulimit' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!ulimit -Sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images ,classes= inference.get_images(0,4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 45.92%\n",
      "Top 5 accuracy is 72.60%\n",
      "Top 1 count is 1837\n",
      "Top 5 count is 2904\n"
     ]
    }
   ],
   "source": [
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 47.52%\n",
      "Top 5 accuracy is 73.45%\n",
      "Top 1 count is 1901\n",
      "Top 5 count is 2938\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(4000,8000)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 46.65%\n",
      "Top 5 accuracy is 72.92%\n",
      "Top 1 count is 1866\n",
      "Top 5 count is 2917\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(8000,12000)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 50.00%\n",
      "Top 5 accuracy is 68.75%\n",
      "Top 1 count is 8\n",
      "Top 5 count is 11\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(12000,12016)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 46.70%\n",
      "Top 5 accuracy is 72.99%\n",
      "Top 1 count is 5612\n",
      "Top 5 count is 8770\n"
     ]
    }
   ],
   "source": [
    "count_top1 = 1837 + 1901 + 1866 + 8\n",
    "count_top5 = 2904 + 2938 + 2917 + 11\n",
    "print(f\"Top 1 accuracy is {count_top1/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 48.05%\n",
      "Top 5 accuracy is 74.70%\n",
      "Top 1 count is 1922\n",
      "Top 5 count is 2988\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(0,4000)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 46.85%\n",
      "Top 5 accuracy is 74.62%\n",
      "Top 1 count is 1874\n",
      "Top 5 count is 2985\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(4000,8000)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 47.75%\n",
      "Top 5 accuracy is 75.17%\n",
      "Top 1 count is 1910\n",
      "Top 5 count is 3007\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(8000,12000)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy is 56.25%\n",
      "Top 5 accuracy is 75.00%\n",
      "Top 1 count is 9\n",
      "Top 5 count is 12\n"
     ]
    }
   ],
   "source": [
    "images ,classes= inference.get_images(12000,12016)\n",
    "\n",
    "inputs = processor(text=mini_values, images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "logits_per_image = outputs.logits_per_image  # 이미지와 텍스트 간 유사도\n",
    "probs = logits_per_image.softmax(dim=-1)  # softmax로 확률 계산\n",
    "p = probs.cpu()\n",
    "\n",
    "mini_values_numpy = np.array(mini_values)\n",
    "count_top1 = 0\n",
    "count_top5 = 0\n",
    "for index in range(len(p)):\n",
    "    top_5 = np.argsort(p[index])[-5:]\n",
    "    top_1 = np.argsort(p[index])[-1:]\n",
    "    top_5_text = p[index][top_5]\n",
    "    top_1_text = p[index][top_1]\n",
    "    if any(mini_dict[classes[index]] in item for item in mini_values_numpy[top_5]):\n",
    "        count_top5+=1\n",
    "    if mini_dict[classes[index]] == mini_values_numpy[top_1]:\n",
    "        count_top1+=1\n",
    "        #print(mini_dict[classes[index]])\n",
    "        #print(mini_values_numpy[top_1])\n",
    "        #print()\n",
    "\n",
    "print(f\"Top 1 accuracy is {count_top1/len(p)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(p)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only text\n",
      "Top 1 accuracy is 46.70%\n",
      "Top 5 accuracy is 72.99%\n",
      "Top 1 count is 5612\n",
      "Top 5 count is 8770\n",
      "\n",
      "a photo of text\n",
      "Top 1 accuracy is 47.56%\n",
      "Top 5 accuracy is 74.83%\n",
      "Top 1 count is 5715\n",
      "Top 5 count is 8992\n",
      "\n",
      "Top 1 accuracy is 0.86%\n",
      "Top 5 accuracy is 1.85%\n",
      "Top 1 count is 103\n",
      "Top 5 count is 222\n"
     ]
    }
   ],
   "source": [
    "print(\"only text\")\n",
    "count_top1 = 1837 + 1901 + 1866 + 8\n",
    "count_top5 = 2904 + 2938 + 2917 + 11\n",
    "print(f\"Top 1 accuracy is {count_top1/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5}\")\n",
    "print()\n",
    "print(\"a photo of text\")\n",
    "count_top1_a = 1922 + 1874 + 1910 + 9\n",
    "count_top5_a = 2988 + 2985 + 3007 + 12\n",
    "print(f\"Top 1 accuracy is {count_top1_a/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {count_top5_a/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1_a}\")\n",
    "print(f\"Top 5 count is {count_top5_a}\")\n",
    "print()\n",
    "print(f\"Top 1 accuracy is {(count_top1_a-count_top1)/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 5 accuracy is {(count_top5_a-count_top5)/len(inference)*100:.2f}%\")\n",
    "print(f\"Top 1 count is {count_top1_a-count_top1}\")\n",
    "print(f\"Top 5 count is {count_top5_a-count_top5}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
