{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd # type: ignore\n",
    "import matplotlib.pyplot as plt # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "from glob import glob\n",
    "import numpy as np # type: ignore\n",
    "import cv2 # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 데이터의 경로와 정보를 가진 파일의 경로를 설정\n",
    "traindata_dir = \"./data/train\"\n",
    "traindata_info_file = \"./data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/data/ephemeral/home/cv20-proj1/level1-imageclassification-cv-20/suyoung')\n",
    "train_data = pd.read_csv(traindata_info_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>image_path</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>n01872401</td>\n",
       "      <td>n01872401/sketch_50.JPEG</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>n02417914</td>\n",
       "      <td>n02417914/sketch_11.JPEG</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>n02106166</td>\n",
       "      <td>n02106166/sketch_3.JPEG</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>n04235860</td>\n",
       "      <td>n04235860/sketch_2.JPEG</td>\n",
       "      <td>382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>n02056570</td>\n",
       "      <td>n02056570/sketch_40.JPEG</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class_name                image_path  target\n",
       "0  n01872401  n01872401/sketch_50.JPEG      59\n",
       "1  n02417914  n02417914/sketch_11.JPEG     202\n",
       "2  n02106166   n02106166/sketch_3.JPEG     138\n",
       "3  n04235860   n04235860/sketch_2.JPEG     382\n",
       "4  n02056570  n02056570/sketch_40.JPEG      80"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0th work done\n",
      "100th work done\n",
      "200th work done\n",
      "300th work done\n",
      "400th work done\n",
      "500th work done\n",
      "600th work done\n",
      "700th work done\n",
      "800th work done\n",
      "900th work done\n",
      "1000th work done\n",
      "1100th work done\n",
      "1200th work done\n",
      "1300th work done\n",
      "1400th work done\n",
      "1500th work done\n",
      "1600th work done\n",
      "1700th work done\n",
      "1800th work done\n",
      "1900th work done\n",
      "2000th work done\n",
      "2100th work done\n",
      "2200th work done\n",
      "2300th work done\n",
      "2400th work done\n",
      "2500th work done\n",
      "2600th work done\n",
      "2700th work done\n",
      "2800th work done\n",
      "2900th work done\n",
      "3000th work done\n",
      "3100th work done\n",
      "3200th work done\n",
      "3300th work done\n",
      "3400th work done\n",
      "3500th work done\n",
      "3600th work done\n",
      "3700th work done\n",
      "3800th work done\n",
      "3900th work done\n",
      "4000th work done\n",
      "4100th work done\n",
      "4200th work done\n",
      "4300th work done\n",
      "4400th work done\n",
      "4500th work done\n",
      "4600th work done\n",
      "4700th work done\n",
      "4800th work done\n",
      "4900th work done\n",
      "5000th work done\n",
      "5100th work done\n",
      "5200th work done\n",
      "5300th work done\n",
      "5400th work done\n",
      "5500th work done\n",
      "5600th work done\n",
      "5700th work done\n",
      "5800th work done\n",
      "5900th work done\n",
      "6000th work done\n",
      "6100th work done\n",
      "6200th work done\n",
      "6300th work done\n",
      "6400th work done\n",
      "6500th work done\n",
      "6600th work done\n",
      "6700th work done\n",
      "6800th work done\n",
      "6900th work done\n",
      "7000th work done\n",
      "7100th work done\n",
      "7200th work done\n",
      "7300th work done\n",
      "7400th work done\n",
      "7500th work done\n",
      "7600th work done\n",
      "7700th work done\n",
      "7800th work done\n",
      "7900th work done\n",
      "8000th work done\n",
      "8100th work done\n",
      "8200th work done\n",
      "8300th work done\n",
      "8400th work done\n",
      "8500th work done\n",
      "8600th work done\n",
      "8700th work done\n",
      "8800th work done\n",
      "8900th work done\n",
      "9000th work done\n",
      "9100th work done\n",
      "9200th work done\n",
      "9300th work done\n",
      "9400th work done\n",
      "9500th work done\n",
      "9600th work done\n",
      "9700th work done\n",
      "9800th work done\n",
      "9900th work done\n",
      "10000th work done\n",
      "10100th work done\n",
      "10200th work done\n",
      "10300th work done\n",
      "10400th work done\n",
      "10500th work done\n",
      "10600th work done\n",
      "10700th work done\n",
      "10800th work done\n",
      "10900th work done\n",
      "11000th work done\n",
      "11100th work done\n",
      "11200th work done\n",
      "11300th work done\n",
      "11400th work done\n",
      "11500th work done\n",
      "11600th work done\n",
      "11700th work done\n",
      "11800th work done\n",
      "11900th work done\n",
      "12000th work done\n",
      "12100th work done\n",
      "12200th work done\n",
      "12300th work done\n",
      "12400th work done\n",
      "12500th work done\n",
      "12600th work done\n",
      "12700th work done\n",
      "12800th work done\n",
      "12900th work done\n",
      "13000th work done\n",
      "13100th work done\n",
      "13200th work done\n",
      "13300th work done\n",
      "13400th work done\n",
      "13500th work done\n",
      "13600th work done\n",
      "13700th work done\n",
      "13800th work done\n",
      "13900th work done\n",
      "14000th work done\n",
      "14100th work done\n",
      "14200th work done\n",
      "14300th work done\n",
      "14400th work done\n",
      "14500th work done\n",
      "14600th work done\n",
      "14700th work done\n",
      "14800th work done\n",
      "14900th work done\n",
      "15000th work done\n"
     ]
    }
   ],
   "source": [
    "folders = []\n",
    "# data 폴더 밑에 canny 폴더를 먼저 만들고 수행 \n",
    "canny_dir = '/data/ephemeral/home/cv20-proj1/level1-imageclassification-cv-20/suyoung/data/canny'\n",
    "\n",
    "for i in range(len(train_data)):\n",
    "    class_name = train_data['class_name'].values[i]\n",
    "    original_image_path = os.path.join(traindata_dir, train_data['image_path'].values[i])\n",
    "    file_name = train_data['image_path'].values[i].split('/')[-1]\n",
    "\n",
    "    # Canny edge detection \n",
    "    image = cv2.imread(original_image_path)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    edge = cv2.Canny(gray, 100, 200)\n",
    "\n",
    "    if class_name in folders:\n",
    "        cv2.imwrite(canny_dir+'/'+train_data['image_path'].values[i], edge)\n",
    "    else:\n",
    "        folders.append(class_name)\n",
    "        os.makedirs(canny_dir+'/'+class_name)\n",
    "        cv2.imwrite(canny_dir+'/'+train_data['image_path'].values[i], edge)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(f'{i}th work done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 셀은 train.py에서 중간에 삽입\n",
    "# 각 class별로 8:2의 비율이 되도록 학습과 검증 데이터를 분리.\n",
    "train_df, val_df = train_test_split(\n",
    "    train_info, \n",
    "    test_size=1-config.TRAIN_RATIO,\n",
    "    stratify=train_info['target'],\n",
    "    random_state=20\n",
    ")\n",
    "\n",
    "# # 새롭게 생성한 canny edge data를 train_df에 해당되는 것만 이동\n",
    "source_dir = '/data/ephemeral/home/cv20-proj1/level1-imageclassification-cv-20/suyoung/data/canny'  # 원본 디렉토리 경로\n",
    "destination_dir = '/data/ephemeral/home/cv20-proj1/level1-imageclassification-cv-20/suyoung/data/train'  # 대상 디렉토리 경로\n",
    "\n",
    "source_folders = os.listdir(source_dir)\n",
    "destination_folders = os.listdir(destination_dir)\n",
    "\n",
    "for i in range(len(destination_folders)):\n",
    "    if destination_folders[i] in source_folders:\n",
    "        folder = destination_folders[i]\n",
    "        image_path_list = train_df[train_df['class_name'] == folder]['image_path'].to_list()\n",
    "        for j in range(len(image_path_list)):\n",
    "            source_file_path = os.path.join(source_dir, image_path_list[j])\n",
    "            file_name = image_path_list[j].split('/')[-1]\n",
    "            new_name = 'edge_detected_' + file_name\n",
    "            destination_file_path = os.path.join(destination_dir, folder, new_name)\n",
    "            shutil.copy2(source_file_path, destination_file_path)\n",
    "\n",
    "# train_info에 추가된 canny edge data를 덧붙임\n",
    "class_name_list = []\n",
    "image_path_list = []\n",
    "target_list = []\n",
    "\n",
    "traindata_folders = os.listdir(traindata_dir)\n",
    "\n",
    "for i in range(len(traindata_folders)):\n",
    "    if traindata_folders[i] != '.DS_Store':\n",
    "        class_name = traindata_folders[i]\n",
    "        class_path = os.path.join(traindata_dir, class_name)\n",
    "        class_target = train_info[train_info['class_name'] == class_name]['target'].unique().item()\n",
    "\n",
    "        # 클래스 폴더에서 이미지별로 path 추출\n",
    "        class_images_list = os.listdir(class_path)\n",
    "        for j in range(len(class_images_list)):\n",
    "            class_image = class_images_list[j]\n",
    "            if class_image.startswith('edge_detected'):\n",
    "                class_image_path = os.path.join(class_name, class_image)\n",
    "                class_name_list.append(class_name)\n",
    "                image_path_list.append(class_image_path)\n",
    "                target_list.append(class_target)\n",
    "\n",
    "# 데이터 프레임에 추가하기 \n",
    "new_data = pd.DataFrame({train_info.columns[0] : class_name_list, \n",
    "                         train_info.columns[1] : image_path_list,\n",
    "                         train_info.columns[2] : target_list})\n",
    "\n",
    "train_info = pd.concat([train_info, new_data], ignore_index=True)\n",
    "train_info = train_info.astype({'target' : 'int'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
